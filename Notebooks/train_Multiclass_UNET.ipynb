{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Getting acces to your google drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "4LSwNQlpXLul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278d5497-b67b-47bc-d185-55c633a73aac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd 'drive/My Drive/ColabNotebooks/UNET/'"
      ],
      "metadata": {
        "id": "YRmVG7BTXO_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69950b8-71f1-424d-9ba2-1c62f3328650"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ColabNotebooks/UNET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z9PLRWKQ9Tcw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as Fun\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.metrics import MeanIoU\n",
        "import csv\n",
        "import random\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNET\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"\n",
        "    A double 3x3 same convolution followed by a Batch Normalization\n",
        "    layer and a ReLU Activation function each.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    \"\"\"\n",
        "    U-Net Network Architecture as described in: https://arxiv.org/abs/1505.04597\n",
        "    But making use of same convolutions and Batch Normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, n_classes, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Contracting path (down)\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Expanding path (up)\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(\n",
        "                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n",
        "            )\n",
        "            self.ups.append(DoubleConv(feature * 2, feature))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
        "        self.final_conv = nn.Conv2d(features[0], n_classes, kernel_size=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        # Step size of 2 because ups contains a upsampling step follow by a double conv\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            # Do the upsampling step\n",
        "            x = self.ups[idx](x)\n",
        "            feature_map = skip_connections[idx//2]\n",
        "\n",
        "            if x.shape != feature_map.shape:\n",
        "                x = TF.resize(x, size=feature_map.shape[2:])\n",
        "\n",
        "            # Concatenate encoder and decoder feature maps from corresponding levels\n",
        "            concat = torch.cat((feature_map, x), dim=1)\n",
        "            # Do the double convolutions\n",
        "            x = self.ups[idx+1](concat)\n",
        "\n",
        "        return self.final_conv(x)"
      ],
      "metadata": {
        "id": "2UQUoZrn-QLh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "\n",
        "class SievesDataset(Dataset):\n",
        "    def __init__(self, image_list, image_dir, mask_dir, transform=None):\n",
        "        self.images = image_list\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #Load image and corresponding mask\n",
        "        img_path = os.path.join(self.image_dir, self.images[index])\n",
        "        mask_path = os.path.join(self.mask_dir, self.images[index].replace(\".jpg\", \"_mask.png\"))\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
        "\n",
        "        # Preprocess mask (for multiclass)\n",
        "        mask[mask == 127.0] = 1\n",
        "        mask[mask == 255.0] = 2\n",
        "\n",
        "        #Data augmentation\n",
        "        if self.transform is not None:\n",
        "            augmentations = self.transform(image=image, mask=mask)\n",
        "            image = augmentations[\"image\"]\n",
        "            mask = augmentations[\"mask\"]\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "4lG5SWfc-WhC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utils\n",
        "\n",
        "class MetricTracker:\n",
        "    def __init__(self, n_classes):\n",
        "        self.total_mean_iou = MeanIoU(num_classes=n_classes)\n",
        "\n",
        "    def calculate_iou(self, preds, targets):\n",
        "        with torch.no_grad():\n",
        "            preds = torch.argmax(preds, dim=1)\n",
        "            preds = preds.cpu().numpy()\n",
        "\n",
        "            # Loop through an individual batch\n",
        "            for pred, target in zip(preds, targets):\n",
        "                target = target.cpu().numpy()\n",
        "                # Update to the IoU over all images in the batch\n",
        "                self.total_mean_iou.update_state(target, pred)\n",
        "\n",
        "    def get(self):\n",
        "        return self.total_mean_iou.result().numpy()\n",
        "\n",
        "\n",
        "def save_checkpoint(state, folder, filename):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    print(f\"Filename = {filename}\")\n",
        "    model_path = os.path.join(folder, filename)\n",
        "    torch.save(state, model_path)\n",
        "\n",
        "\n",
        "def load_checkpoint(model, folder, filename):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    print(f\"Filename = {filename}\")\n",
        "    checkpoint_path = os.path.join(folder, filename)\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "        image_list,\n",
        "        image_dir,\n",
        "        mask_dir,\n",
        "        batch_size,\n",
        "        transform,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "):\n",
        "    # Create train dataset + specify the transforms / directories\n",
        "    ds = SievesDataset(\n",
        "        image_list,\n",
        "        image_dir=image_dir,\n",
        "        mask_dir=mask_dir,\n",
        "        transform=transform,\n",
        "    )\n",
        "\n",
        "    # Create training loader + specify training dataset and parameters + shuffle order randomly\n",
        "    loader = DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    return loader\n",
        "\n",
        "\n",
        "def compute_iou_per_class(mean_iou):\n",
        "    # Matrix: Row = true labels | Columns = predicted labels\n",
        "    # [0,0] = Number of pixels where, True label = 0 & Predicted label = 0\n",
        "    # [0,1] = Number of pixels where, True label = 0 & Predicted label = 1\n",
        "    pred_per_class = np.array(mean_iou.get_weights()[0])\n",
        "\n",
        "    # IoU per class\n",
        "    # Sum column and row 0 to get all the TP + FP + FN per class\n",
        "    # Subtract the diagonal not to double count TP's\n",
        "    sum_row = np.sum(pred_per_class, axis=1)\n",
        "    sum_column = np.sum(pred_per_class, axis=0)\n",
        "    # True Positives\n",
        "    diagonal = np.diagonal(pred_per_class)\n",
        "    # Union per class\n",
        "    union_per_class = sum_row + sum_column - diagonal\n",
        "\n",
        "    iou_per_class = diagonal/union_per_class\n",
        "\n",
        "    return iou_per_class\n",
        "\n",
        "\n",
        "def evaluate_model(loader, model, device=\"cuda\"):\n",
        "    n_classes = 3\n",
        "    mean_iou = MeanIoU(num_classes=n_classes)\n",
        "\n",
        "    # Evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Loop over batches\n",
        "    for x, labels in loader:\n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = torch.argmax(model(x), dim=1)\n",
        "            preds = preds.cpu().numpy()\n",
        "\n",
        "            # Loop through an individual batch\n",
        "            for pred, true_label in zip(preds, labels):\n",
        "                true_label = true_label.cpu().numpy()\n",
        "                # Update to the IoU over all images in the batch\n",
        "                mean_iou.update_state(true_label, pred)\n",
        "\n",
        "    iou_per_class = compute_iou_per_class(mean_iou)\n",
        "\n",
        "    # Turn training mode back on\n",
        "    model.train()\n",
        "\n",
        "    return iou_per_class, mean_iou.result().numpy()\n",
        "\n",
        "\n",
        "def save_predictions_as_imgs(\n",
        "        loader, model, batch_size, folder, device=\"cuda\"\n",
        "):\n",
        "    # Check if directory exist or create a new\n",
        "    if not os.path.isdir(folder):\n",
        "        os.mkdir(folder)\n",
        "\n",
        "    # Evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for idx_main, (x, labels), in enumerate(loader):\n",
        "        x = x.to(device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = torch.argmax(model(x), dim=1)\n",
        "            preds = preds.cpu().numpy()\n",
        "\n",
        "            # Save images in batch as individual images for inspection\n",
        "            for idx_inner, (pred, true_label) in enumerate(zip(preds, labels)):\n",
        "                # Calculate ongoing unique image number\n",
        "                img_num = idx_main * batch_size + idx_inner\n",
        "\n",
        "                # Turn categorical to grayscale values for easy inspection\n",
        "                pred[pred == 1] = 127.0\n",
        "                pred[pred == 2] = 255.0\n",
        "                # Turn categorical to grayscale values for easy inspection\n",
        "                true_label[true_label == 1] = 127.0\n",
        "                true_label[true_label == 2] = 255.0\n",
        "\n",
        "                # Save predicted segmentations\n",
        "                cv.imwrite(f\"{folder}/pred_{img_num}.png\", pred)\n",
        "                # Save corresponding true segmentations\n",
        "                cv.imwrite(f\"{folder}/true_{img_num}.png\", true_label.numpy())\n",
        "\n",
        "    # Turn training mode back on\n",
        "    model.train()\n",
        "\n",
        "def write_to_csv(csv_path, epoch=None, train_loss=None, train_miou=None,\n",
        "                 val_miou=None, class_iou=None, create_header=False, test_set=False):\n",
        "    # Write for test set evaluation\n",
        "    if test_set:\n",
        "        header = [\"mean_iou\", \"iou_class1\", \"iou_class2\", \"iou_class3\"]\n",
        "        with open(csv_path, \"w\", encoding=\"UTF8\", newline=\"\") as csv_file:\n",
        "            writer = csv.writer(csv_file)\n",
        "            writer.writerow(header)\n",
        "            writer.writerow([val_miou, class_iou[0], class_iou[1], class_iou[2]])\n",
        "\n",
        "        return\n",
        "\n",
        "    # Create new header for train / validation set\n",
        "    if create_header:\n",
        "        header = [\"epoch\", \"train_loss\", \"train_miou\", \"val_miou\", \"val_iou_class1\", \"val_iou_class2\", \"val_iou_class3\"]\n",
        "        with open(csv_path, \"w\", encoding=\"UTF8\", newline=\"\") as csv_file:\n",
        "            writer = csv.writer(csv_file)\n",
        "            writer.writerow(header)\n",
        "\n",
        "        return\n",
        "\n",
        "    # Add data row to train / validation csv\n",
        "    with open(csv_path, \"a\", encoding=\"UTF8\", newline=\"\") as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([epoch, train_loss, train_miou, val_miou, class_iou[0], class_iou[1], class_iou[2]])\n",
        "\n",
        "def save_splits(folder, train, val, test):\n",
        "    for file, name in zip([train, val, test], [\"train\", \"val\", \"test\"]):\n",
        "        with open(f\"{folder}/{name}_split.json\", \"w\") as f:\n",
        "            json.dump(file, f, indent=2)\n",
        "\n",
        "def plot_train_val(model_dir, model_name):\n",
        "    # Plot training / validation metrics\n",
        "    # Read in the data into a pandas dataframe\n",
        "    df = pd.read_csv(f\"{model_dir}{model_name}.csv\")\n",
        "\n",
        "    # Training loss\n",
        "    plt.plot(df[\"epoch\"], df[\"train_loss\"])\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('Training Loss')\n",
        "    plt.title(\"Training Loss per Epoch\")\n",
        "    plt.locator_params(axis=\"x\", integer=True, tight=True)\n",
        "    plt.show()\n",
        "\n",
        "    # Training mIoU\n",
        "    plt.plot(df[\"epoch\"], df[\"train_miou\"])\n",
        "    plt.plot(df[\"epoch\"], df[\"val_miou\"])\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('Mean IoU')\n",
        "    plt.title(\"Mean IoU per Epoch\")\n",
        "    plt.locator_params(axis=\"x\", integer=True, tight=True)\n",
        "    plt.legend([\"Train\", \"Validation\"])\n",
        "    plt.show()\n",
        "\n",
        "    # Validation Class IoU\n",
        "    plt.plot(df[\"epoch\"], df[\"val_iou_class1\"], color=\"red\")\n",
        "    plt.plot(df[\"epoch\"], df[\"val_iou_class2\"], color=\"blue\")\n",
        "    plt.plot(df[\"epoch\"], df[\"val_iou_class3\"], color=\"green\")\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('Validation Class IoU')\n",
        "    plt.title(\"Validation Class IoU per Epoch\")\n",
        "    plt.locator_params(axis=\"x\", integer=True, tight=True)\n",
        "    plt.legend([\"Class 1 (Background)\", \"Class 2 (Holes)\", \"Class 3 (Debris)\"])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gB5Eislw-uDZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Focal Loss\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        ce_loss = nn.functional.cross_entropy(predictions, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        return torch.mean(focal_loss)"
      ],
      "metadata": {
        "id": "qqrEC_ZrxVxB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "# Hyper parameters & settings\n",
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 7\n",
        "NUM_EPOCHS = 50\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_HEIGHT = 720\n",
        "IMAGE_WIDTH = 720\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "IMAGE_DIR = \"data/images/\"\n",
        "MASK_DIR = \"data/masks/\"\n",
        "SAVED_IMAGES_DIR = \"saved_images/\"\n",
        "MODEL_DIR = 'saved_models/'\n",
        "MODEL_NAME = f'epochs{NUM_EPOCHS}_batch{BATCH_SIZE}_h{IMAGE_HEIGHT}_w{IMAGE_WIDTH}_lr{LEARNING_RATE}_RandomResizedCrops_focalloss'\n",
        "N_CLASSES = 3\n",
        "TRAIN_RATIO = 0.8               # 80%\n",
        "VAL_RATIO = TRAIN_RATIO + 0.1   # 10% | Remaining % -> 10% is for the test set\n",
        "\n",
        "\n",
        "def train_fn(loader, model, optimizer, loss_fn, scaler, epoch):\n",
        "    loop = tqdm(loader)\n",
        "    epoch_metrics = MetricTracker(N_CLASSES)\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.to(device=DEVICE).long()\n",
        "\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast():\n",
        "            predictions = model(data)\n",
        "            loss = loss_fn(predictions, targets)\n",
        "\n",
        "            # Full epoch metrics: cumulative metrics of the batches\n",
        "            epoch_metrics.calculate_iou(predictions, targets)\n",
        "\n",
        "        # backwards\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # update tqdm loop\n",
        "        loop.set_description(f\"Epoch: {epoch}/{NUM_EPOCHS}\")\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    return loss.item(), epoch_metrics.get()"
      ],
      "metadata": {
        "id": "ofC82mre_vlH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN\n",
        "\n",
        "train_transform = A.Compose(\n",
        "        [\n",
        "            A.RandomResizedCrop(width=IMAGE_WIDTH, height=IMAGE_HEIGHT, scale=(0.1, 1.0), p=1.0),\n",
        "            A.Rotate(limit=35, p=1.0),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.1),\n",
        "            A.Normalize(\n",
        "                mean=[0.0, 0.0, 0.0],\n",
        "                std=[1.0, 1.0, 1.0],\n",
        "                max_pixel_value=255.0\n",
        "            ),\n",
        "            ToTensorV2()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "val_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "        A.Normalize(\n",
        "            mean=[0.0, 0.0, 0.0],\n",
        "            std=[1.0, 1.0, 1.0],\n",
        "            max_pixel_value=255.0\n",
        "        ),\n",
        "        ToTensorV2()\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create train / val / test split randomly\n",
        "all_images = os.listdir(IMAGE_DIR)\n",
        "random.seed(42)\n",
        "random.shuffle(all_images)\n",
        "train_split, val_split, test_split = np.split(\n",
        "    all_images,\n",
        "    [int(TRAIN_RATIO*len(all_images)), int(VAL_RATIO*len(all_images))]\n",
        ")\n",
        "\n",
        "# Save splits for later evaluation -> especially the test split for this trained model\n",
        "save_splits(MODEL_DIR, list(train_split), list(val_split), list(test_split))\n",
        "\n",
        "train_loader = get_loader(train_split, IMAGE_DIR, MASK_DIR, BATCH_SIZE,\n",
        "                            train_transform, NUM_WORKERS, PIN_MEMORY\n",
        "                            )\n",
        "\n",
        "val_loader = get_loader(val_split, IMAGE_DIR, MASK_DIR, BATCH_SIZE,\n",
        "                        val_transform, NUM_WORKERS, PIN_MEMORY\n",
        "                        )\n",
        "\n",
        "\n",
        "print(f\"Training for: {NUM_EPOCHS} epochs | Batchsize : {BATCH_SIZE} | WxH: {IMAGE_WIDTH}x{IMAGE_HEIGHT} | LR: {LEARNING_RATE} | Focal Loss\")\n",
        "\n",
        "model = UNET(in_channels=3, n_classes=N_CLASSES).to(DEVICE)\n",
        "loss_fn = FocalLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Load model for further training\n",
        "if LOAD_MODEL:\n",
        "    load_checkpoint(model, f\"model_map\", f\"model_name\")\n",
        "\n",
        "# Gradient scaling, inorder to prevent vanishing or exploding gradients\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Dummy variable model performance comparison\n",
        "# Holding the epoch & Mean_IoU of when the model performed best\n",
        "best_mean_iou = (0, -1)\n",
        "\n",
        "csv_path = os.path.join(MODEL_DIR, f\"{MODEL_NAME}.csv\")\n",
        "write_to_csv(csv_path, create_header=True)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Train model and return the loss\n",
        "    train_loss, train_miou = train_fn(train_loader, model, optimizer, loss_fn, scaler, epoch+1)\n",
        "\n",
        "    # Save model\n",
        "    checkpoint = {\n",
        "        \"state_dict\" : model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "\n",
        "    # Evaluate the current training epoch on the validation data\n",
        "    val_class_iou, val_miou = evaluate_model(val_loader, model, device=DEVICE)\n",
        "    write_to_csv(csv_path, epoch+1, train_loss, train_miou, val_miou, val_class_iou)\n",
        "\n",
        "    print(f\"Train mIoU: {train_miou} | Validation mIoU: {val_miou} | Validation Class IoU: {val_class_iou}\")\n",
        "\n",
        "    if val_miou > best_mean_iou[1]:\n",
        "        print(f\"New best validation mIoU: {val_miou} | Previous best mIoU: {best_mean_iou[1]} in epoch: {best_mean_iou[0]}.\")\n",
        "        # save_checkpoint(checkpoint, folder=f\"saved_models/\", filename=f\"checkpoint_epoch{epoch+1}.pth.tar\")\n",
        "        # For now just overwrite previous best model\n",
        "        save_checkpoint(checkpoint, folder=MODEL_DIR, filename=f\"{MODEL_NAME}.pth.tar\")\n",
        "\n",
        "        # Save some examples to a folder for inspection\n",
        "        save_predictions_as_imgs(\n",
        "            val_loader, model, BATCH_SIZE, folder=f\"{SAVED_IMAGES_DIR}/epoch{epoch+1}/\", device=DEVICE\n",
        "        )\n",
        "\n",
        "        # Update best IoU\n",
        "        best_mean_iou = (epoch+1, val_miou)"
      ],
      "metadata": {
        "id": "9ImYoiPT_3Ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45a6534-251e-4aae-9edd-6982ca651800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for: 50 epochs | Batchsize : 7 | WxH: 720x720 | LR: 0.0001 | Focal Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 1/50:  43%|████▎     | 35/81 [02:14<02:15,  2.94s/it, loss=0.0861]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training / validation metrics\n",
        "\n",
        "plot_train_val(MODEL_DIR, MODEL_NAME)"
      ],
      "metadata": {
        "id": "qJWJpvRVZ9Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the Test set\n",
        "\n",
        "TEST_DIR = \"saved_models/eval_test/\"\n",
        "# Change to load another model\n",
        "# MODEL_NAME = \"model_name\"\n",
        "# Change to save read from another data split\n",
        "FILE_NAME = \"test_split.json\"\n",
        "\n",
        "# Trying with transform first\n",
        "val_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "        A.Normalize(\n",
        "            mean=[0.0, 0.0, 0.0],\n",
        "            std=[1.0, 1.0, 1.0],\n",
        "            max_pixel_value=255.0\n",
        "        ),\n",
        "        ToTensorV2()\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Retrieve test split for this model\n",
        "with open(f\"{MODEL_DIR}{FILE_NAME}\") as f:\n",
        "    test_json = f.read()\n",
        "# Create split list\n",
        "test_split = json.loads(test_json)\n",
        "\n",
        "# Load trained model\n",
        "model = UNET(in_channels=3, n_classes=N_CLASSES).to(DEVICE)\n",
        "load_checkpoint(model, MODEL_DIR, f\"{MODEL_NAME}.pth.tar\")\n",
        "\n",
        "# Create test ds + loader\n",
        "test_loader = get_loader(test_split, IMAGE_DIR, MASK_DIR, BATCH_SIZE,\n",
        "                        val_transform, NUM_WORKERS, PIN_MEMORY)\n",
        "\n",
        "# Evaluate mIoU and class IoU\n",
        "class_iou, miou = evaluate_model(test_loader, model, device=DEVICE)\n",
        "print(f\"----------------------------------------------------------------------------------------------------------------\")\n",
        "print(f\"Evaluating model on the test set | mIoU: {miou}\")\n",
        "print(f\"IoU class 1 (background): {class_iou[0]} | IoU class 2 (holes): {class_iou[1]} | IoU class 3 (debris): {class_iou[2]}\")\n",
        "print(f\"----------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "# Save metrics\n",
        "csv_path = os.path.join(TEST_DIR, f\"{MODEL_NAME}.csv\")\n",
        "write_to_csv(csv_path, val_miou=miou, class_iou=class_iou, test_set=True)\n",
        "\n",
        "# Save predictions and masks for inspection\n",
        "save_predictions_as_imgs(\n",
        "    test_loader, model, BATCH_SIZE, folder=f\"{TEST_DIR}/examples/\", device=DEVICE\n",
        ")"
      ],
      "metadata": {
        "id": "dkzGr5OJZdjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Close runtime to save valuable compute hours\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "cACOK70konrS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}